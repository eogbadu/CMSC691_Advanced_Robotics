{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ffeb1e",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce24377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "import os\n",
    "import tokenizermodule as tm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe3ce4",
   "metadata": {},
   "source": [
    "Import excel file with our input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ed95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"oneandtwowithfilepathtest.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730fe3e",
   "metadata": {},
   "source": [
    "Split the data set into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"Dialogue Move\"]\n",
    "features = df[\"Commander\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68730622",
   "metadata": {},
   "source": [
    "Print the labels value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413ae47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce736563",
   "metadata": {},
   "source": [
    "Get the number of sentences in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf478f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences = features.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76597d",
   "metadata": {},
   "source": [
    "Clean and parse the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\\n Cleaning and parsing the feature data\\n\")\n",
    "clean_features = []\n",
    "for i in range( 0, len(features)):\n",
    "    if( (i+1)%100 == 0 ):\n",
    "        print (\"Sentence %d of %d\\n\" % ( i+1, num_sentences )  )  \n",
    "\n",
    "    clean_features.append(\" \".join(tm.processSentence(features[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de4fff",
   "metadata": {},
   "source": [
    "Print the top 5 sentences on the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a44fd",
   "metadata": {},
   "source": [
    "Create the bag of words model for the feature set, , and convert to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Creating the bag of words...\\n\")\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(clean_features)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69254961",
   "metadata": {},
   "source": [
    "Split features and target into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=1, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d123685c",
   "metadata": {},
   "source": [
    "Print out the labels value counts for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eea843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd725be",
   "metadata": {},
   "source": [
    "Initialize a Random Forest classifier with 100 trees\n",
    "Fit the forest to the training set.\n",
    "This may take a few minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb60a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Training the random forest (this may take a while)...\")\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit( X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3271af7",
   "metadata": {},
   "source": [
    "Make predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db14c6b",
   "metadata": {},
   "source": [
    "View accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8398337",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de229114",
   "metadata": {},
   "source": [
    "View confusion matrix for test data and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6aa74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376111c",
   "metadata": {},
   "source": [
    "Get and reshape confusion matrix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred_test)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a4485",
   "metadata": {},
   "source": [
    "Build the plot and add labels to the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad5f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "class_names = ['Explore', 'Move', 'Send Image', 'Stop', 'Turn']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for BOW Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42feaf19",
   "metadata": {},
   "source": [
    "View the classification report for test data and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd567b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
